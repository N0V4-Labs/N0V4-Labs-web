<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="How PHALANX's memory system uses a 2 GB budget with frame, pool, and heap allocators to keep allocation costs predictable.">
  <title>Inside PHALANX's Memory System: 2 GB On Purpose</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&family=Merriweather:ital,wght@0,300;0,400;0,700;0,900;1,400&family=Montserrat:wght@400;700;900&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
  <nav class="navbar">
    <div class="container">
      <div class="nav-brand">
        <h1><a href="index.html" style="color: inherit; text-decoration: none;">ziX Performance Labs</a></h1>
      </div>
      <ul class="nav-menu">
        <li><a href="about.html">About</a></li>
      </ul>
    </div>
  </nav>
</header>

<main>
  <div class="container">
    <section class="blog-content">
      <article class="blog-post">
        <h2>Inside PHALANX's Memory System: 2 GB On Purpose</h2>
        <div class="meta">
          October 25, 2025
        </div>
        <div class="content">
          <p>
            Here’s what tends to happen once you try to run a 144&nbsp;FPS mech game at scale:
          </p>
          <p>
            At the beginning you lean on the default allocator. It looks fine. Memory graphs are noisy but tolerable, frame times are mostly OK, and the occasional spike is easy to blame on “debug mode” or “editor overhead.”
          </p>
          <p>
            Then you turn on full gameplay: ECS, physics, particles, replay, UI, networking. The allocator turns into the hidden boss fight. Latency spikes become hard to reproduce. Fragmentation creeps up over long matches. Profiling turns into an archaeology dig through <code>operator new</code>.
          </p>
          <p>
            PHALANX’s memory system exists so we don’t have to live there.
          </p>
          <p>
            It’s built around a very small set of constraints:
          </p>
          <ul>
            <li>There is a hard budget (~2&nbsp;GB) with an explicit split between frame, pool, and heap usage.</li>
            <li>Allocations come from explicit, named allocators, not the global heap by accident.</li>
            <li>Every byte that matters shows up in Tracy as either a timeline or a graph.</li>
            <li>When we exceed a budget, that’s a design problem, not a surprise.</li>
          </ul>
          <p>
            Same pattern as the ECS layer: write down the rules first, then write code that has a chance of obeying them.
          </p>

          <hr>

          <h3>Numbers first</h3>
          <p>
            The budget lives in <code>phalnx::memory::BudgetConfig</code> (<code>budget.h</code>):
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">budget.h</p>
            <pre class="article-code-text cpp">// phalnx/memory/budget.h

struct BudgetConfig {
  std::size_t frame_allocator_budget = 16 * 1024 * 1024;         // 16 MB
  std::size_t pool_allocator_budget  = 512 * 1024 * 1024;        // 512 MB
  std::size_t heap_allocator_budget  = 1536 * 1024 * 1024;       // 1.5 GB
  std::size_t total_budget           = 2ULL * 1024 * 1024 * 1024; // 2 GB

  float warning_threshold = 0.80f;   // 80%
  float error_threshold   = 0.95f;   // 95%
};</pre>
          </div>

          <p>
            Which translates to:
          </p>
          <ul>
            <li>Frame allocator (per-frame scratch): <strong>16&nbsp;MB</strong></li>
            <li>Pool allocators (entities / effects / similar): <strong>512&nbsp;MB</strong></li>
            <li>General heap (assets, systems, everything long-lived): <strong>1.5&nbsp;GB</strong></li>
            <li>Total runtime budget: <strong>2&nbsp;GB</strong></li>
          </ul>
          <p>
            The budget isn’t a claim about every possible platform; it’s the working assumption for the machines PHALANX is targeting.
          </p>
          <p>
            On top of that, each allocator sets explicit per-operation targets in its own header:
          </p>
          <ul>
            <li>
              <code>FrameAllocator</code> (<code>frame_allocator.h</code>):<br>
              Allocation target <strong>&lt; 50&nbsp;ns</strong>; <code>Reset()</code> around <strong>10&nbsp;ns</strong>.
            </li>
            <li>
              <code>PoolAllocator</code> (<code>pool_allocator.h</code>):<br>
              Allocation target <strong>&lt; 60&nbsp;ns</strong>, deallocation <strong>&lt; 80&nbsp;ns</strong>.
            </li>
            <li>
              <code>FreeListAllocator</code> (<code>free_list_allocator.h</code>):<br>
              Allocation target <strong>&lt; 100&nbsp;ns</strong> (90th percentile), deallocation <strong>&lt; 50&nbsp;ns</strong>.
            </li>
            <li>
              <code>FlecsAllocatorBridge</code> (<code>flecs_allocator.h</code> / <code>.cpp</code>):<br>
              Target <strong>&lt; 100–200&nbsp;ns</strong> per routed allocation and a measured drop in frame-time variance (for example, from ~18% down below 5% P99) when Flecs stops using the CRT allocator.
            </li>
          </ul>
          <p>
            If a change moves us far outside those ranges, that’s treated as a regression, not a “maybe it’s fine” discussion.
          </p>

          <hr>

          <h3>The core API: <code>phalnx::memory::IAllocator</code></h3>
          <p>
            The memory layer is built around a single interface in <code>allocator.h</code>:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">allocator.h</p>
            <pre class="article-code-text cpp">namespace phalnx::memory {

struct AllocationResult {
  void*       ptr  = nullptr;
  std::size_t size = 0;

  [[nodiscard]] explicit operator bool() const noexcept {
    return ptr != nullptr;
  }
};

class IAllocator {
 public:
  virtual ~IAllocator() = default;

  IAllocator(const IAllocator&amp;)            = delete;
  IAllocator&amp; operator=(const IAllocator&amp;) = delete;
  IAllocator(IAllocator&amp;&amp;)                 = delete;
  IAllocator&amp; operator=(IAllocator&amp;&amp;)      = delete;

  [[nodiscard]] virtual void* Allocate(
      std::size_t size,
      std::size_t alignment = alignof(std::max_align_t)) = 0;

  virtual void Deallocate(void* ptr, std::size_t size) = 0;

  [[nodiscard]] virtual bool Owns(const void* ptr) const = 0;

  [[nodiscard]] virtual std::size_t GetUsedBytes() const { return 0; }
  [[nodiscard]] virtual std::size_t GetPeakBytes() const { return 0; }

  template &lt;typename T&gt;
  [[nodiscard]] T* New() {
    return static_cast&lt;T*&gt;(Allocate(sizeof(T), alignof(T)));
  }

  template &lt;typename T&gt;
  [[nodiscard]] T* NewArray(std::size_t count) {
    if (!count) return nullptr;
    return static_cast&lt;T*&gt;(Allocate(sizeof(T) * count, alignof(T)));
  }

  template &lt;typename T&gt;
  void Delete(T* ptr) {
    Deallocate(static_cast&lt;void*&gt;(ptr), sizeof(T));
  }

  template &lt;typename T&gt;
  void DeleteArray(T* ptr, std::size_t count) {
    if (!ptr || !count) return;
    Deallocate(static_cast&lt;void*&gt;(ptr), sizeof(T) * count);
  }

  [[nodiscard]] virtual AllocationResult AllocateResult(
      std::size_t size,
      std::size_t alignment = alignof(std::max_align_t)) {
    void* ptr = Allocate(size, alignment);
    return {ptr, ptr ? size : 0};
  }

 protected:
  IAllocator() = default;
};

} // namespace phalnx::memory</pre>
          </div>

          <p>
            A few constraints this encodes:
          </p>
          <ul>
            <li><strong>No exceptions.</strong> Failure is represented as <code>nullptr</code>. Callers are expected to branch on that and decide what to drop or degrade.</li>
            <li><strong>Alignment is explicit.</strong> <code>Allocate</code> takes an alignment; implementations assert that it’s a power of two.</li>
            <li><strong>Ownership is testable.</strong> <code>Owns</code> lets diagnostic tools and safety checks assert that a given pointer really belongs to that allocator.</li>
            <li><strong>Usage stats are standardized.</strong> <code>GetUsedBytes</code> / <code>GetPeakBytes</code> give a consistent way to feed telemetry and budget tracking.</li>
          </ul>
          <p>
            Everything else—frame allocator, pools, free-list heap, Flecs bridge, thread-local allocators—sits on top of this interface.
          </p>

          <hr>

          <h3>Frame allocator: memory that evaporates on <code>Reset</code></h3>
          <p>
            <code>FrameAllocator</code> (<code>frame_allocator.h</code>) is a linear bump allocator tuned for per-frame temporary allocations:
          </p>
          <ul>
            <li>Single contiguous buffer.</li>
            <li>Single offset into that buffer.</li>
            <li><code>Allocate</code> bumps the offset with alignment padding.</li>
            <li><code>Deallocate</code> is a no-op.</li>
            <li><code>Reset()</code> sets the offset back to zero.</li>
          </ul>
          <p>
            Configuration:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">frame_allocator.h</p>
            <pre class="article-code-text cpp">inline constexpr std::size_t kDefaultFrameAllocatorCapacity =
    16 * 1024 * 1024; // 16 MB

inline constexpr std::size_t kCacheLineSize = 64;</pre>
          </div>

          <p>
            The class:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">frame_allocator.h</p>
            <pre class="article-code-text cpp">class FrameAllocator final : public IAllocator {
 public:
  explicit FrameAllocator(
      std::size_t capacity = kDefaultFrameAllocatorCapacity,
      const char* name     = "FrameAllocator");

  ~FrameAllocator() override;

  [[nodiscard]] void* Allocate(
      std::size_t size,
      std::size_t alignment = alignof(std::max_align_t)) override;

  void Deallocate(void* ptr, std::size_t size) override;

  void Reset() noexcept;

  [[nodiscard]] std::size_t GetUsedBytes() const override;
  [[nodiscard]] std::size_t GetPeakBytes() const override;

  [[nodiscard]] std::size_t GetCapacity() const noexcept;
  [[nodiscard]] std::size_t GetFreeBytes() const noexcept;

 private:
  void*        buffer_      = nullptr;
  std::size_t  capacity_    = 0;
  std::size_t  offset_      = 0;
  std::size_t  peak_usage_  = 0;
  const char*  name_        = nullptr;
};</pre>
          </div>

          <p>
            Construction allocates a cache-line–aligned buffer, tracks it via <code>PHALNX_TRACY_ALLOC(buffer_, capacity_, name_)</code>, and asserts that the allocation succeeded. Destruction calls <code>PHALNX_TRACY_FREE</code> before returning the memory to the OS.
          </p>
          <p>
            The contract is strict:
          </p>
          <ul>
            <li>Everything returned from a <code>FrameAllocator</code> is invalid after <code>Reset()</code>.</li>
            <li>Storing those pointers in long-lived structures is undefined behavior.</li>
            <li><code>Deallocate</code> exists only to satisfy <code>IAllocator</code>; it doesn’t reclaim anything.</li>
          </ul>
          <p>
            The payoff is that allocation is just a bounds check and a pointer bump, and reset is a single store. Physics, rendering, and ECS can all build complex temporary structures without fighting the general heap or worrying about fine-grained frees.
          </p>

          <hr>

          <h3>Pool allocators: fixed-size objects at O(1)</h3>
          <p>
            For “lots of objects of the same size that live longer than a frame” (projectiles, minions, particles, pooled ECS nodes), PHALANX uses <code>PoolAllocator&lt;T, Capacity&gt;</code> (<code>pool_allocator.h</code>):
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">pool_allocator.h</p>
            <pre class="article-code-text cpp">template &lt;typename T, std::size_t Capacity&gt;
class PoolAllocator final : public IAllocator {
 public:
  static_assert(Capacity &gt; 0, "Pool capacity must be positive");
  static_assert(sizeof(T) &gt;= sizeof(void*),
                "Object type must be at least pointer-sized");

  explicit PoolAllocator(const char* name = "PoolAllocator");

  ~PoolAllocator() override;

  PoolAllocator(const PoolAllocator&amp;)            = delete;
  PoolAllocator&amp; operator=(const PoolAllocator&amp;) = delete;
  PoolAllocator(PoolAllocator&amp;&amp;)                 = delete;
  PoolAllocator&amp; operator=(PoolAllocator&amp;&amp;)      = delete;

  [[nodiscard]] T* Allocate();        // returns uninitialized T or nullptr
  void            Deallocate(T* ptr); // returns slot to free-list

  template &lt;typename... Args&gt;
  [[nodiscard]] T* Construct(Args&amp;&amp;... args) {
    T* ptr = Allocate();
    if (!ptr) return nullptr;
    new (ptr) T(std::forward&lt;Args&gt;(args)...);
    return ptr;
  }

  void Destroy(T* ptr) {
    if (!ptr) return;
    ptr-&gt;~T();
    Deallocate(ptr);
  }

  [[nodiscard]] void* Allocate(
      std::size_t size,
      std::size_t alignment = alignof(std::max_align_t)) override;

  void Deallocate(void* ptr, std::size_t size) override;

  [[nodiscard]] bool Owns(const void* ptr) const override;

  [[nodiscard]] std::size_t GetUsedBytes() const override;
  [[nodiscard]] std::size_t GetPeakBytes() const override;

 private:
  struct FreeNode { FreeNode* next; };

  void*       buffer_         = nullptr;
  FreeNode*   free_list_head_ = nullptr;
  std::size_t free_count_     = 0;
  std::size_t peak_usage_     = 0;
  const char* name_           = nullptr;
};</pre>
          </div>

          <p>
            Internally, the pool is just:
          </p>
          <ul>
            <li>A fixed-size buffer.</li>
            <li>A singly-linked list of free slots (<code>FreeNode</code> stored in the slot when it’s free).</li>
          </ul>
          <p>
            Key properties:
          </p>
          <ul>
            <li><strong>O(1) allocate / free.</strong> Allocation pops the free-list head; deallocation pushes a node back.</li>
            <li><strong>Explicit failure mode.</strong> When the free list is empty, <code>Allocate</code> / <code>Construct</code> return <code>nullptr</code>. The caller decides whether to drop a projectile, deny a spawn, or degrade visuals.</li>
            <li><strong>No fragmentation.</strong> All slots are exactly <code>sizeof(T)</code>, so any free slot can serve any allocation.</li>
          </ul>
          <p>
            An example budgeted pool:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">pool_allocator.h (usage)</p>
            <pre class="article-code-text cpp">constexpr std::size_t kMaxProjectiles = 10'000;
PoolAllocator&lt;Projectile, kMaxProjectiles&gt; projectile_pool("ProjectilePool");

Projectile* p = projectile_pool.Construct(args...);
if (!p) {
  // Pool exhausted; apply gameplay-level policy.
}

projectile_pool.Destroy(p);</pre>
          </div>

          <p>
            Pools enforce the idea that “how many of these can we afford?” is a design decision, not a side effect of players spawning too much stuff.
          </p>

          <hr>

          <h3>Free-list allocator: the general heap</h3>
          <p>
            For long-lived, variable-size allocations—assets, systems, UI trees, scripting runtimes—PHALANX uses <code>FreeListAllocator</code> (<code>free_list_allocator.h</code> / <code>.cpp</code>).
          </p>
          <p>
            Configuration:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">free_list_allocator.h</p>
            <pre class="article-code-text cpp">inline constexpr std::size_t kNumSizeClasses        = 16;
inline constexpr std::size_t kMinBlockSize          = 8;
inline constexpr std::size_t kMaxSizeClass          = 128 * 1024;      // 128 KB
inline constexpr std::size_t kDefaultFreeListHeapSize = 512 * 1024 * 1024; // 512 MB
inline constexpr std::size_t kFreeListCacheLineSize = 64;</pre>
          </div>

          <p>
            Core internal structures:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">free_list_allocator.h</p>
            <pre class="article-code-text cpp">struct FreeBlock {
  std::size_t size;
  FreeBlock*  next;
};

struct AllocHeader {
  std::size_t size;
  std::uint8_t size_class;
  std::uint8_t padding[7];
};

inline constexpr std::size_t kAllocHeaderSize = sizeof(AllocHeader);

class FreeListAllocator final : public IAllocator {
 public:
  explicit FreeListAllocator(
      std::size_t heap_size = kDefaultFreeListHeapSize,
      const char* name      = "FreeListAllocator");

  ~FreeListAllocator() override;

  [[nodiscard]] void* Allocate(
      std::size_t size,
      std::size_t alignment = alignof(std::max_align_t)) override;

  void Deallocate(void* ptr, std::size_t size) override;

  [[nodiscard]] const char* GetName() const override;
  [[nodiscard]] std::size_t GetCapacity() const override;
  [[nodiscard]] bool        Owns(const void* ptr) const override;

  [[nodiscard]] std::size_t GetUsedBytes() const override;
  [[nodiscard]] std::size_t GetPeakBytes() const override;

  std::size_t Coalesce(); // explicit coalescing pass

 private:
  void*       heap_           = nullptr;
  std::size_t heap_size_      = 0;
  std::size_t allocated_bytes_ = 0;
  std::size_t peak_bytes_     = 0;
  std::array&lt;FreeBlock*, kNumSizeClasses&gt; bins_{};
  const char* name_           = nullptr;

  // ... helpers: FindFreeBlock, InsertFreeBlock, RemoveFreeBlock, etc ...
};</pre>
          </div>

          <p>
            Behavior:
          </p>
          <ul>
            <li>Requests up to <code>kMaxSizeClass</code> are rounded into one of the 15 power-of-two bins.</li>
            <li>Larger allocations go through an overflow path that scans a larger block list.</li>
            <li>Every allocation gets an <code>AllocHeader</code> with the size and size-class index, so <code>Deallocate</code> can return it to the right bin and optionally coalesce with neighbors.</li>
            <li><code>Coalesce()</code> lets systems explicitly merge adjacent free blocks to control fragmentation, instead of relying on background magic.</li>
          </ul>
          <p>
            The default heap size is 512&nbsp;MB, but the <strong>design budget</strong> for heap usage is 1.5&nbsp;GB via <code>BudgetConfig</code>. That leaves room to scale the backing heap or to have more than one instance if needed, while still tracking against a single global budget.
          </p>

          <hr>

          <h3>Thread-local and size-class allocators for Flecs</h3>
          <p>
            For ECS memory specifically, there’s a tighter integration layer in <code>flecs_allocator.h</code> and related headers:
          </p>
          <ul>
            <li><code>thread_local_allocators.h</code> / <code>.cpp</code></li>
            <li><code>small_block_pool_allocator.h</code> / <code>.cpp</code></li>
            <li><code>size_class_pool_allocator.h</code> / <code>.cpp</code></li>
            <li><code>flecs_allocator.h</code> / <code>.cpp</code></li>
          </ul>

          <h4><code>ThreadLocalAllocators</code></h4>
          <p>
            <code>ThreadLocalAllocators</code> gives each thread its own small <code>FrameAllocator</code>:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">thread_local_allocators.h</p>
            <pre class="article-code-text cpp">struct ThreadLocalConfig {
  static constexpr std::size_t kFrameAllocatorSize   = 4 * 1024 * 1024; // 4 MB
  static constexpr std::size_t kMaxThreads           = 32;
  static constexpr std::size_t kMaxThreadLocalSize   = 256;             // bytes
};

class ThreadLocalAllocators {
 public:
  static void Initialize();
  static void Shutdown();

  [[nodiscard]] static void* Allocate(
      std::size_t size,
      std::size_t alignment = 16);

  static void Deallocate(void* ptr, std::size_t size);

  static void ResetAll();

  static FrameAllocator&amp; GetThreadAllocator();

  struct Stats {
    std::size_t active_threads;
    std::size_t total_capacity;
    std::size_t total_used;
    std::size_t total_peak;
    std::size_t allocations;
  };
};</pre>
          </div>

          <p>
            Allocations up to 256&nbsp;bytes can go through a per-thread <code>FrameAllocator</code> with zero contention. Public documentation makes the intent explicit: allocations ≤ <code>kMaxThreadLocalSize</code> use these thread-local buffers; larger requests fall through to other allocators.
          </p>

          <h4>Small and medium pools for Flecs</h4>
          <p>
            Two additional allocators target Flecs’ allocation patterns:
          </p>
          <ul>
            <li>
              <code>SmallBlockPoolAllocator</code> (<code>small_block_pool_allocator.h</code>):<br>
              For <strong>0–256&nbsp;byte</strong> blocks, thread-safe, size-class based, tuned for Flecs’ small metadata allocations. Uses 5 sizes (<code>32, 64, 128, 192, 256</code>&nbsp;bytes) with preconfigured capacities.
            </li>
            <li>
              <code>SizeClassPoolAllocator</code> (<code>size_class_pool_allocator.h</code>):<br>
              For <strong>257–4096&nbsp;byte</strong> blocks, thread-safe, size-class based pools with capacities configured for common Flecs component array sizes.
            </li>
          </ul>
          <p>
            Those two, plus <code>FreeListAllocator</code>, form the actual routing target for Flecs.
          </p>

          <h4><code>FlecsAllocatorBridge</code></h4>
          <p>
            <code>FlecsAllocatorBridge</code> wires Flecs’ <code>ecs_os_api_t</code> into PHALANX’s allocator stack:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">flecs_allocator.h</p>
            <pre class="article-code-text cpp">enum class AllocatorSource : std::uint32_t {
  ThreadLocal   = 0, // 0–256B
  SizeClassPool = 1, // 257–4096B
  FreeList      = 2, // &gt;4096B
  Invalid       = 0xFFFFFFFF
};

struct FlecsAllocationHeader {
  std::size_t     size;       // requested size
  std::size_t     total_size; // including header + padding
  AllocatorSource source;     // where to free
};

class FlecsAllocatorBridge {
 public:
  static void Initialize();
  static void Shutdown();
  static bool  IsInitialized();

  static SmallBlockPoolAllocator&amp;  GetSmallAllocator();   // 0–256B
  static SizeClassPoolAllocator&amp;   GetMediumAllocator();  // 257–4096B
  static FreeListAllocator&amp;        GetLargeAllocator();   // &gt;4096B

  struct Stats {
    std::size_t total_allocations;
    std::size_t total_deallocations;
    std::size_t current_bytes;
    std::size_t peak_bytes;
    std::size_t live_allocations;
  };

  static Stats GetStats();
};</pre>
          </div>

          <p>
            Routing rules are explicitly size-based:
          </p>
          <ul>
            <li><code>0–256</code>&nbsp;bytes → thread-safe small-block pools.</li>
            <li><code>257–4096</code>&nbsp;bytes → <code>SizeClassPoolAllocator</code>.</li>
            <li><code>&gt;4096</code>&nbsp;bytes → <code>FreeListAllocator</code> dedicated to large Flecs allocations (tables, big component arrays).</li>
          </ul>
          <p>
            Each allocation gets a <code>FlecsAllocationHeader</code> prepended; <code>FlecsAllocatorBridge</code> uses that header to free from the correct allocator and to maintain per-source statistics. All of this is instrumented into Tracy using the same <code>PHALNX_TRACY_ALLOC</code> / <code>PHALNX_TRACY_FREE</code> macros as the rest of the system.
          </p>

          <hr>

          <h3>Tracy integration: making memory visible</h3>
          <p>
            The bridge to Tracy lives in <code>phalnx/profiling/tracy_memory.h</code>.
          </p>
          <p>
            At the lowest level:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">tracy_memory.h</p>
            <pre class="article-code-text cpp">#ifdef TRACY_ENABLE
#define PHALNX_TRACY_ALLOC(ptr, size, pool_name) TracyAllocN(ptr, size, pool_name)
#define PHALNX_TRACY_FREE(ptr, pool_name)        TracyFreeN(ptr, pool_name)
#define ENTITY_MANAGER_ZONE_SCOPED(name)         ZoneScopedN(name)
#else
#define PHALNX_TRACY_ALLOC(ptr, size, pool_name) ((void)0)
#define PHALNX_TRACY_FREE(ptr, pool_name)        ((void)0)
#define ENTITY_MANAGER_ZONE_SCOPED(name)         ((void)0)
#endif</pre>
          </div>

          <p>
            On top of that there are a few helpers:
          </p>
          <ul>
            <li><code>TrackedAllocation&lt;T, Allocator&gt;</code>: wraps an allocator and emits <code>PHALNX_TRACY_ALLOC</code> / <code>PHALNX_TRACY_FREE</code> around the lifetime of a single object.</li>
            <li><code>TrackBatchAllocation</code> / <code>UntrackBatchAllocation</code>: convenience functions for “one large buffer, many internal users” patterns.</li>
            <li>Memory usage helpers that pair with <code>BudgetTracker</code>.</li>
          </ul>
          <p>
            This means every allocator (frame, pool, free-list, Flecs bridge) can show up in Tracy as a named pool, and their usage timelines can be aligned with system timings and ECS iteration zones.
          </p>

          <hr>

          <h3>Budgets as first-class entities</h3>
          <p>
            <code>BudgetTracker</code> in <code>budget.h</code> ties real usage back to <code>BudgetConfig</code>:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">budget.h</p>
            <pre class="article-code-text cpp">enum class BudgetCategory : std::uint8_t {
  kFrame = 0,
  kPool  = 1,
  kHeap  = 2,
  kTotal = 3,
  kCount = 4
};

enum class AlertLevel : std::uint8_t {
  kNone    = 0,
  kWarning = 1,
  kError   = 2
};

struct BudgetAlert {
  BudgetCategory   category;
  AlertLevel       level;
  std::size_t      current_bytes;
  std::size_t      budget_bytes;
  float            utilization_percent;
  std::string_view category_name;
  std::string_view level_name;
};

using AlertCallback = std::function&lt;void(const BudgetAlert&amp;)&gt;;

class BudgetTracker {
 public:
  explicit BudgetTracker(const BudgetConfig&amp; config = BudgetConfig{});

  void SetFrameUsage(std::size_t bytes) noexcept;
  void SetPoolUsage (std::size_t bytes) noexcept;
  void SetHeapUsage (std::size_t bytes) noexcept;

  void SetAllUsage(std::size_t frame_bytes,
                   std::size_t pool_bytes,
                   std::size_t heap_bytes) noexcept;

  void CheckBudgets();
  void LogToTracy() const;

  void SetAlertCallback(AlertCallback cb);

  // ... GetFrameUsage(), GetPoolUsage(), GetHeapUsage(), GetTotalUsage(),
  //     and utilization accessors ...
};</pre>
          </div>

          <p>
            The typical wiring looks like:
          </p>

          <div class="article-code draw-left-line">
            <p class="article-code-file mark-section">budget.h (usage)</p>
            <pre class="article-code-text cpp">BudgetConfig   config;
BudgetTracker  tracker{config};

tracker.SetAlertCallback([](const BudgetAlert&amp; alert) {
  LOG_WARNING(Memory,
              "Budget alert: {} at {:.1f}% ({}/{} bytes)",
              alert.category_name,
              alert.utilization_percent,
              alert.current_bytes,
              alert.budget_bytes);
});

// Once per frame:
tracker.SetFrameUsage(frame_allocator.GetUsedBytes());
tracker.SetPoolUsage(total_pool_bytes);
tracker.SetHeapUsage(heap_allocator.GetUsedBytes());
tracker.CheckBudgets();
tracker.LogToTracy();</pre>
          </div>

          <p>
            <code>LogToTracy()</code> emits plots with names:
          </p>
          <ul>
            <li><code>Memory/Frame (MB)</code></li>
            <li><code>Memory/Pool (MB)</code></li>
            <li><code>Memory/Heap (MB)</code></li>
            <li><code>Memory/Total (MB)</code></li>
          </ul>
          <p>
            and the corresponding percentage series:
          </p>
          <ul>
            <li><code>Memory/Frame %</code></li>
            <li><code>Memory/Pool %</code></li>
            <li><code>Memory/Heap %</code></li>
            <li><code>Memory/Total %</code></li>
          </ul>
          <p>
            If <code>Memory/Pool (MB)</code> trends upward and never comes back down, there’s a leak in or near some pool. If <code>Memory/Frame (MB)</code> spikes exactly when physics does, you know where to start looking.
          </p>

          <hr>

          <h3>How it’s meant to be used</h3>
          <p>
            The machinery above is mostly low-level. The interesting behavior comes from how it’s applied across systems.
          </p>

          <h4>Physics: per-thread scratch, no allocator contention</h4>
          <p>
            The physics workload (lots of small, short-lived structures across multiple threads) maps directly onto:
          </p>
          <ul>
            <li><code>ThreadLocalAllocators</code> and per-thread <code>FrameAllocator</code> instances for contact graphs, queries, and solver temporaries.</li>
            <li>Dedicated <code>PoolAllocator</code> instances for recurring structures like <code>ContactPoint</code>, <code>RaycastHit</code>, and other fixed-size objects.</li>
          </ul>
          <p>
            This keeps physics allocations out of the general heap and prevents allocator locks from showing up as mysterious stalls.
          </p>

          <h4>Burst effects: pre-allocating the spike</h4>
          <p>
            Effects like stagger, knockback, and other bursty mechanics are modeled as “rare but potentially huge spikes.”
          </p>
          <p>
            The pattern there is:
          </p>
          <ul>
            <li>Size a dedicated pool for the worst plausible case (for example, every mech staggered at once plus margin).</li>
            <li>Use the pool in a double-buffered way: one half for “this frame”, one half for “next frame”.</li>
            <li>Reset or reuse the inactive half in bulk rather than freeing individual events.</li>
          </ul>
          <p>
            The goal is to remove “massive but rare heap bursts” from the problem space entirely.
          </p>

          <h4>ECS and memory alignment</h4>
          <p>
            The ECS side is built to align with this memory stack:
          </p>
          <ul>
            <li>Flecs allocations for tables, component arrays, and metadata run through <code>FlecsAllocatorBridge</code>, which routes them to small-block pools, size-class pools, or the large <code>FreeListAllocator</code>.</li>
            <li>Transient ECS views or staging structures fit naturally on top of <code>FrameAllocator</code> and, for small pieces, the thread-local layer.</li>
            <li>Long-lived registries and tooling (for example, component registries) sit on the free-list heap but are visible in Tracy and budget tracking.</li>
          </ul>
          <p>
            The essential point is that the typical “20k–100k entities, multiple systems per frame” path does <strong>not</strong> talk to the CRT allocator at all.
          </p>

          <hr>

          <h3>Rules that actually matter</h3>
          <p>
            Most of the safety and performance comes from simple rules enforced consistently across this stack:
          </p>
          <ol>
            <li><strong>Allocators do not throw.</strong> Errors are surfaced as <code>nullptr</code> and <code>BudgetAlert</code>s, not exceptions.</li>
            <li><strong>Frame allocations die at <code>Reset()</code>.</strong> Any API that takes a <code>FrameAllocator&amp;</code> is understood to be dealing in short-lived memory. Storing those pointers is on the caller and is explicitly undefined.</li>
            <li><strong>Pool exhaustion is a design signal.</strong> When a pool runs out, that’s reported via a <code>nullptr</code> and handled in gameplay code. The fallback is not “just hit the general heap and hope.”</li>
            <li><strong>Alignment is explicit and checked.</strong> Alignment parameters must be powers of two; invalid values trip assertions. That prevents “only breaks with wider SIMD” bugs from hiding inside the allocator.</li>
            <li><strong>Telemetry is mandatory in development.</strong> Tracy integration, budget plots, and allocator stats are compiled out in shipping builds, but development and test builds are expected to run with them enabled. If there’s no graph, it doesn’t count as “understood.”</li>
          </ol>

          <hr>

          <h3>Why this shape</h3>
          <p>
            The end state the memory system is aiming at is pretty modest:
          </p>
          <ul>
            <li>A concrete budget and a way to see when reality diverges from it.</li>
            <li>Clear separation between <strong>frame</strong>, <strong>pool</strong>, and <strong>heap</strong> style allocations.</li>
            <li>Allocators that are fast because they’re allowed to impose strict lifetime and size rules.</li>
            <li>Instrumentation that makes misbehavior obvious instead of surprising.</li>
          </ul>
          <p>
            From there, the roadmap looks straightforward:
          </p>
          <ul>
            <li>Attach specific ECS archetypes and systems to explicit pools / size classes so “too many projectiles” shows up as “<code>ProjectilePool</code> at 95% capacity”, not as a random heap spike.</li>
            <li>Tie asset streaming into <code>FreeListAllocator</code> and <code>BudgetTracker</code>, so content can see exactly which packs push the 2&nbsp;GB budget.</li>
            <li>Build in-engine visualization that overlays memory graphs with ECS iteration and system timings to make cross-cutting regressions debuggable in one place.</li>
          </ul>
          <p>
            The intent is not to invent a new allocator. It’s to make memory as boring and observable as possible, so effort can go into the things PHALANX actually cares about: mechs, maps, projectiles, and the fact that there are tens of thousands of entities moving every frame <strong>without</strong> the allocator turning into the bottleneck.
          </p>
        </div>
      </article>
    </section>
  </div>
</main>

<footer>
  <div class="container">
    <p>
      <a href="https://github.com/N0V4-Labs" style="color: var(--link-color); text-decoration: none;">github</a>
      &nbsp;•&nbsp;
      <a href="about.html" style="color: var(--link-color); text-decoration: none;">about</a>
    </p>
  </div>
</footer>
</body>
</html>
